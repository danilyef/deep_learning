{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramm_dict = {}\n",
    "\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        bigram = (ch1,ch2)\n",
    "        bigramm_dict[bigram] = bigramm_dict.get(bigram,0) + 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store bigramm into 2 dim array\n",
    "import torch\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "vocab_size = len(chars)\n",
    "\n",
    "#tokenization:\n",
    "char_to_int = {char:index +1 for index ,char in enumerate(chars)}\n",
    "char_to_int['.'] = 0 #for \"start\" and \"end\" of a string\n",
    "\n",
    "int_to_char = {index+1:char for index,char in enumerate(chars)}\n",
    "int_to_char[0] = '.'\n",
    "\n",
    "vocab_size = len(int_to_char)\n",
    "\n",
    "counts = torch.zeros(vocab_size,vocab_size,dtype= torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        index_1 = (char_to_int[ch1])\n",
    "        index_2 = char_to_int[ch2]\n",
    "        counts[index_1,index_2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating a probability\n",
    "probability = counts[0].float() \n",
    "probability = probability / torch.sum(probability)\n",
    "\n",
    "#sampling charachters from probability distribution:\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "torch.multinomial(input = probability ,num_samples = 1,replacement = True,generator = g)\n",
    "probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor\n",
      "axx\n",
      "minaymoryles\n",
      "kondlaisah\n",
      "anchshizarie\n",
      "odaren\n",
      "iaddash\n",
      "h\n",
      "jhinatien\n",
      "egushl\n",
      "h\n",
      "br\n",
      "a\n",
      "jayn\n",
      "ilemannariaenien\n",
      "be\n",
      "f\n",
      "akiinela\n",
      "trttanakeroruceyaaxatona\n",
      "lamoynayrkiedengin\n"
     ]
    }
   ],
   "source": [
    "#Bigramm predictions\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "probability = counts.float()\n",
    "probability /=  torch.sum(probability,dim = 1,keepdim = True) #broadcasting rules, which we align on the right! Look up Pytorch documentation\n",
    "\n",
    "# /= operatuons is faster -> doesn't create additional memory under the hood\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    index = 0\n",
    "    word = []\n",
    "    while True:\n",
    "        p = probability[index]\n",
    "        sample = torch.multinomial(input = p ,num_samples = 1,replacement = True,generator = g).item()\n",
    "        if sample != 0:\n",
    "            word.append(int_to_char[sample])\n",
    "            index = sample\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(''.join(word))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
